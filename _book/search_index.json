[
["index.html", "Urban Informatics Toolkit Chapter 1 Welcome 1.1 What is Urban Informatics 1.2 What to expect 1.3 Reminders 1.4 Setting the Context: Big Data 1.5 outline / notes 1.6 Other notes", " Urban Informatics Toolkit Josiah Parry 2020-02-02 Chapter 1 Welcome Welcome to the Urban Informatics Toolkit! This book will provide you with an introduction to some of the history of Urban Informatics as a field, important concepts in the field, and provide you with the skills required to jumpstart your own exploration of the urban commons. 1.1 What is Urban Informatics 1.2 What to expect This book is partitioned into chapters where each goes over a small subset of skills that is important to know and a few case studies. the first half of the book will introduce you to the basic tools that you will need to know to become self-sufficient. From there on, we will work with case studies that also introduce new topics and further more advances skills In Part II each chapter, with a few exceptions, will introduce you to a social phenomenon. We will ask a question, and use a relevant dataset to answer this question. While we work to approach each question, we will pause to learn about the tools that we are using, understand what they are doing and why. There will always be a TL;DR for each chapter recapping what we covered, and links to further resources. technical chapters will be interspersed with non-techinical chapters. 1.3 Reminders Learning to program can be exceptionally difficult at times. It can be a roller coaster of emotions. It is expected that you will not understand everything the first go around. Do not get down on yourself. I encourage you to take breaks and not push yourself too hard. I understand you have deadlines, but sometimes it is better if you take a break, eat a healthy snack, go exercise, sleep, be social, etc and then come back. You will be much happier and your work will be even better and that I promise you! Perhaps I am showing my cards a bit too much, but I have always found that with tough assignments it is better to go to bed early and finish them in the morning than it is to stay up exceptionally late. Moral of that story is, get some sleep and take care of yourself! I’ll be sure to remind you from time to time. 1.4 Setting the Context: Big Data The study of Urban Informatics is inherently intertwined with big data. Working with big data requires a set of skills that extends beyond quantitative and qualitative analysis expertise. Students need to know how to access, manipulate, analyze, communicate and share data artifacts. The intention of this practicum is to develop educational content to cultivate an expertise in data. An online text and accompanying exercises will be created to teach students data science in a manner that is tailored toward Urban Informatics studies. Writing this content will provide an opportunity to synthesize the learnings and skills taught in the Urban Informatics program. The manner in which it will be done will also further access to the field and assist in the cultivation of future students. I have always struggled with overly academic writing and overly technical and obtuse descriptions of concepts, tasks, and phenomena that can be written in easy to understand ways. my goal for this text is to provide you with a non-technical instruction to a technical topic. I want this to be friendly and not adversarial nor patronizing. I will do my best to try and explain this language and topics the way that I would to my friends over a beer. 1.5 outline / notes intro is what is ui What is administrative data Current examples of the data driven city Why we need to learn data with theory The data workflow Question then data Data then questions new approach due to massive data There are many insights yet to be discovered R The hard part is getting started. I want to make this as easy as possible with social science and UI examples bear with me for a bit. * Basics as a calculator * Visualization / Visualizing relationships / Visuializing relationships * the type of the data that we have will dictate how we visualize it * Univariate * Bivariate * Data Manipulation * filtering data Tidy and untidy data * tidy data: * this is just to introduce you to the idea and get an idea of what it looks like. No need to understand the code or anything that will show up afterwards. * the principles * demonstrate what it looks like The boring part data structures Administrative data data cleaning manopulatoon Aggregation Introduce interacting with public data via webportals and APIs Geospatial analysis: data are often grounded in space its important to understand where things happen 3 Common data that are associated with space 311 - point (vector data) census tracts - polygon (vector) sattelite imagery - raster (we wont cover this) polygon is the most simple to work with visualization of aggregate data aggregating by polygon (building permits) points are a bit trickier often we want to join this Text analysis unstructured text as data what is the scope and limitations of text data? working with text data: stop words tokenization 1.6 Other notes I will say these data and this data interchangably. I apologize for that. "],
["the-basics.html", "Chapter 2 The basics 2.1 installing RStudio 2.2 The RStudio IDE 2.3 R Projects 2.4 Functions and Packages", " Chapter 2 The basics 2.1 installing RStudio 2.2 The RStudio IDE 2.3 R Projects 2.4 Functions and Packages outline - install the tidyverse - the tidyverse is a collection of packages that make data analysis and cleaning and everythingg else a lot easier install.packages(&quot;tidyverse&quot;) a package is a collection of functions that make life easier. functions are bits of code that do things. we will use a lot of functions throughout. we will dive into this in more depth later on. You can usually recognize a function by the parentheses at the end i.e. function() think about the anatomy of a function: function name and arguments i will be refering to “function arugments” a TON so please internalize this. we will review making functions later. But using functions, oof. Main stay arguments are unquoted the way we load this package for use with the library() function (a little meta, lol) this one line of code will install the packages that we need to do this work. Don’t be too concerned about what a package is. We will go over this in more detail later. Very simply, a package is a collection of functions that make certain things possible or easier to do in R. We like to use packages because reinventing the wheel is never fun. install.packages(&quot;tidyverse&quot;) "],
["visual-analysis.html", "Chapter 3 01 - Visual Analysis 3.1 Exploratory analysis 3.2 The American Community Survey", " Chapter 3 01 - Visual Analysis 3.1 Exploratory analysis https://r4ds.had.co.nz/explore-intro.html iteration this chapter focuses on visualization the process of exploratory anlaysis is naturally inductive 3.2 The American Community Survey we’ll work with data from the american community survey. this is data you will get really familiar with what is the acs and why do we love it? https://www.vox.com/explainers/2015/12/3/9845152/acs-survey-defunded random sample of individuals across the us random samples are used as they representative and statistically non-biased the information is used to determine funding tells us about age, ethnicity, country of origin, occupation, education, voting behavior, etc. this information is available in the decennial census (in the constitution) ACS tells us about rates rather than the actual number of people in a thing one of the major problems is that some populations are under-represented https://prospect.org/economy/insidious-way-underrepresent-minorities/ What is the relationship between education and income? we have a data frame loaded this is very similar to a table in excel each column is a variable acs_edu ## # A tibble: 1,456 x 7 ## med_house_income less_than_hs hs_grad some_coll bach white black ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 105735 0.0252 0.196 0.221 0.325 0.897 0.0122 ## 2 69625 0.0577 0.253 0.316 0.262 0.885 0.0171 ## 3 70679 0.0936 0.173 0.273 0.267 0.733 0.0795 ## 4 74528 0.0843 0.253 0.353 0.231 0.824 0.0306 ## 5 52885 0.145 0.310 0.283 0.168 0.737 0.0605 ## 6 64100 0.0946 0.294 0.317 0.192 0.966 0.00256 ## 7 37093 0.253 0.394 0.235 0.101 0.711 0.0770 ## 8 87750 0.0768 0.187 0.185 0.272 0.759 0.0310 ## 9 97417 0.0625 0.254 0.227 0.284 0.969 0.00710 ## 10 43384 0.207 0.362 0.262 0.124 0.460 0.105 ## # … with 1,446 more rows we can visualize the relationship to get a better understanding. we can look at income and college grad rates start building a visualization with ggplot() function with the acs_edu object. Functions are characterised by the parentheses at the end of them. Functions do things. Objects hold information. ggplot(acs_edu) we add to this plot determine what we want to plot with the aesthetics aes() function inside of the ggplot(). want to specify x and y. These are called arguments. To set argument we use the = sign. set x to bach and y to med_house_income ggplot(acs_edu, aes(x = bach, y = med_house_income)) notice how the plot is being filled a bit more? now we need to specify what type of plot we will be creating. add geometry, or geoms. We use the plus sign + to signify that we are adding on top of the basic graph there are many different kinds of charts we can use we will get into these a bit more later. a common way of visualizing a relationship between two variables is with a scatterplot a scatter plot graphs points for each x and y pair. you’ve likely made a few of these in your primary education to add points to the graph we use geom_point(), remember, we are adding a layer so we use the plus sign for legibility we add each new layer on a new line. R will indent for you. Good style is important. We’ll get into this later ggplot(acs_edu, aes(x = bach, y = med_house_income)) + geom_point() notice that there is a positive linear trend. lets break that down: when the point point up to the right, that is positive, down to the left is negative. for each unit we go up on the x (bach) we tend to go up on the y (hh income) linear means it resembles a line what are we looking for in a scatter plot? we’re looking for low variation and a consistent pattern or line we want the points to be very close imagine we drew a line going through the middle of the points, we’d want each point to be either on that line or extremely close. if the line is further away, that means there is a lot more variation to finish this up we can add some informative labels we will add a labels layer with the function labs() give them more legible labels. we will give each axis a better name and give the plot a title the arguments we will set to the labs function are x, y and title. Rather intuitive, huh? x = “% of population with a Bachelor’s Degree” y = “Median Household Income” title = “Relationship between Education and Income” note that for each argument I have a new line. again, this helps with legibility ggplot(acs_edu, aes(x = bach, y = med_house_income)) + geom_point() + labs(x = &quot;% of population with a Bachelor&#39;s Degree&quot;, y = &quot;Median Household Income&quot;, title = &quot;Relationship between Education and Income&quot;) what can we determine from this graph? in the sociology literature there is a lot about the education gap between white and black folks can we see this in a graph? we can modify our existing plot to illustrate this too. we can map the % white to the color of the chart we add to this within the aesthetics. The aes()thetics is where we will determine things like size, group, shape, etc. set the color argument to the white column while we’re at it, we can add a subtitle to inform that we’re also coloring by % white ggplot(acs_edu, aes(x = bach, y = med_house_income, color = white)) + geom_point() + labs(x = &quot;% of population with a Bachelor&#39;s Degree&quot;, y = &quot;Median Household Income&quot;, title = &quot;Relationship between Education and Income&quot;, subtitle = &quot;Colored by whiteness&quot;) what can we conclude now? "],
["reading-data.html", "Chapter 4 Reading data 4.1 Background 4.2 Actually Reading Data 4.3 Other common data formats", " Chapter 4 Reading data We spent the last chapter performing our first exploratory visual analysis. From our visualizations we were able to inductively conlcude that as both median household income and the proportion of the population with a bachelors degree increases, so does the share of the population is white. This is a finding we will work to address empirically at a later point. While we were able to make wonderful visualizations, we did skip a number of steps in the exploratory analysis process! Arguably most importantly we skipped the importing of our datasets. The ACS dataset was already loaded into R for you. This almost always will not be the case. As such, we’re going to spend this chapter learning about some of the common data formats that you will often work with. { image of the visualization step } 4.1 Background There are three general sources where we as social scientists will recieve or access data: 1) text files, 2) databases, and 3) application programming interfaces (APIs). Frankly, though this is the age of “big data,” we are not always able to interface directly with these sources. But through partnership efforts between the public and private we able to share data. For example, BARIs work with the Boston Police Department provides them with annual access to crime data. But BARIs access is limited. They do not have credentials to log in to the database and perform their own queries. What they are usually presented with is a flat text file(s) that contains the data requisite for analysis. And this is what we will focus in this chapter. Flat text files will be sufficient for 85% of all of your data needs Now, what do I mean by flat text file? A flat text file is a file that stores data in plain text—I know, this seems somewhat confusing. In otherwords, you can open up a text file and actually read the data with your own eyes or a screenreader. For a long while tech pundits believed—and some still do—that text data will be a thing of the past. Perhaps this may be true in the future, but plain text still persists and there are some good reasons for that. Since plain text is extremely simple it is lightweight and usually does not take up that much memory. Also, because there is no fancy embelishing of the data in a plain text file, they can be easily shared from machine to machine without concern of dependent tools and software. Not to mention that we humans can actually be rather hands on and inspect the source of the data ourselves. 4.2 Actually Reading Data Within the tidyverse there is a package called readr which we use for reading in rectangular data from text files. Aside: I am still unsure if it is pronounced read-arr or read-er. So just do your best. I just threw the phrase rectangular data at you. It is only fair to actually describe what that means. If you were to look at rectangular data in something like excel it would resemble a rectangle. In fancy speak, rectangular data is a two-dimensional data structure with rows and columns. We will learn more about the “proper” way to shape rectangular data in the “tidying data” chapter. For now, all you need to know is that there are rows and columns in rectangular data. To get started, let us load the tidyverse. This will load readr for us. library(tidyverse) You most likely have seen and encountered flat text files in the wild inthe form of a csv. It is important to know what csv stands for because it will help you understand what it actually is. it stands for comma separated values. _csv_s are a flat text data file where the data is rectangular! Each new line of the file indicates that there is a new row. Within each row, each comma indicates a new column. If you opened one up in a text editor like text edit or notepad a csv would look something like below. column_a, column_b, column_c, 10, &quot;these are words&quot;, .432, 1, &quot;and more words&quot;, 1.11 To read a csv we use the readr::read_csv() function. read_csv() will read in the csv file and create a tibble. A tibble is type of a data structure that we will be interacting with the most throughout this book. A tibble is a rectangular data structure with rows and columns. Since a csv contains rectangular data, it is natural for it to be stored in a tibble. Note: the syntax above is used for referencing a function from a namespace (package name). The syntax is pkgname::function(). This means the read_csv() function from the package readr. This is something you will see frequently on websites like StackOverflow. Have a look at the arguments of read_csv() by entering ?read_csv() into the console. You will notice that there are many arguments that you can set. These are there to give you a lot of control over how R will read your data. For now, and most of the time, we do not need to be concerned about these extra arguments. All we need to do is tell R where our data file lives. If you haven’t deduced from the help page yet, we will supply only the first argument file. This argument is either a path to a file, a connection, or literal data (either a single string or a raw vector). Note: When you see the word string, that means values inside of quotations—i.e. “this is a string”. We will read in the dataset that was already loaded in the first chapter. These data are stored in the file named acs_edu.csv. We can try reading this as the file path. read_csv(&quot;acs_edu.csv&quot;) ## Error: &#39;acs_edu.csv&#39; does not exist in current working directory ## (&#39;/Users/Josiah/GitHub/urban-commons-toolkit&#39;). Oops. We’ve got red text and that is never fun. Except, this is a very important error message that, frankly, you will get a lot. Again it says: Error: ‘acs_edu.csv’ does not exist in current working directory I’ve bolded two portions of this error message. Take a moment to think through what this error is telling you. For those of you who weren’t able to figure it out or just too impatient (like myself): this error is telling us that R looked for the file we provided acs_edu.csv but it could not find it. This usually means to me that I’ve either misspelled the file name, or I have not told R to look in the appropriate folder (a.k.a. directory). acs_edu.csv actually lives in a directory called data. To tell R—or any computer system, really—where that file is we write data/acs_edu.csv. This tells R to first enter the data directory and then look for the acs_edu.csv file. Now, read the acs_edu.csv file! read_csv(file = &quot;data/acs_edu.csv&quot;) ## Parsed with column specification: ## cols( ## med_house_income = col_double(), ## less_than_hs = col_double(), ## hs_grad = col_double(), ## some_coll = col_double(), ## bach = col_double(), ## white = col_double(), ## black = col_double() ## ) ## # A tibble: 1,456 x 7 ## med_house_income less_than_hs hs_grad some_coll bach white black ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 105735 0.0252 0.196 0.221 0.325 0.897 0.0122 ## 2 69625 0.0577 0.253 0.316 0.262 0.885 0.0171 ## 3 70679 0.0936 0.173 0.273 0.267 0.733 0.0795 ## 4 74528 0.0843 0.253 0.353 0.231 0.824 0.0306 ## 5 52885 0.145 0.310 0.283 0.168 0.737 0.0605 ## 6 64100 0.0946 0.294 0.317 0.192 0.966 0.00256 ## 7 37093 0.253 0.394 0.235 0.101 0.711 0.0770 ## 8 87750 0.0768 0.187 0.185 0.272 0.759 0.0310 ## 9 97417 0.0625 0.254 0.227 0.284 0.969 0.00710 ## 10 43384 0.207 0.362 0.262 0.124 0.460 0.105 ## # … with 1,446 more rows This is really good! Except, all that happened was that the function was ran. The data it imported was not saved anywhere which means we will not be able to interact with it. What we saw was the output of the data. In order to interact with the data we need to assign it to an object. Reminder: we assign object with the assignment operator &lt;-—i.e. new_obj &lt;- read_csv(&quot;file-path.csv&quot;). Objects are things that we interact with such as a tibble. Functions such as read_csv() usually, but not always, modify or create objects. In order to interact with the data, let us store the output into a tibble object called acs. acs &lt;- read_csv(file = &quot;data/acs_edu.csv&quot;) Notice how now there was no data printed in the console. This is a good sign! It means that R read the data and stored it properly into the acs object. When we don’t store the function results, the results are (usually) printed out. To print an object, we can just type it’s name into the console. acs ## # A tibble: 1,456 x 7 ## med_house_income less_than_hs hs_grad some_coll bach white black ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 105735 0.0252 0.196 0.221 0.325 0.897 0.0122 ## 2 69625 0.0577 0.253 0.316 0.262 0.885 0.0171 ## 3 70679 0.0936 0.173 0.273 0.267 0.733 0.0795 ## 4 74528 0.0843 0.253 0.353 0.231 0.824 0.0306 ## 5 52885 0.145 0.310 0.283 0.168 0.737 0.0605 ## 6 64100 0.0946 0.294 0.317 0.192 0.966 0.00256 ## 7 37093 0.253 0.394 0.235 0.101 0.711 0.0770 ## 8 87750 0.0768 0.187 0.185 0.272 0.759 0.0310 ## 9 97417 0.0625 0.254 0.227 0.284 0.969 0.00710 ## 10 43384 0.207 0.362 0.262 0.124 0.460 0.105 ## # … with 1,446 more rows This is sometimes a little overwhelming of a view. For previewing data, the function dplyr::glimpse() (there is the namespace notation again) is a great option. Try using the function glimpse() with the first argument being the acs object. glimpse(acs) ## Observations: 1,456 ## Variables: 7 ## $ med_house_income &lt;dbl&gt; 105735, 69625, 70679, 74528, 52885, 64100, 3709… ## $ less_than_hs &lt;dbl&gt; 0.02515518, 0.05773956, 0.09364548, 0.08426318,… ## $ hs_grad &lt;dbl&gt; 0.19568768, 0.25307125, 0.17332284, 0.25298192,… ## $ some_coll &lt;dbl&gt; 0.2211696, 0.3157248, 0.2726736, 0.3534052, 0.2… ## $ bach &lt;dbl&gt; 0.32473048, 0.26167076, 0.26677159, 0.23124279,… ## $ white &lt;dbl&gt; 0.8972737, 0.8849885, 0.7328322, 0.8235779, 0.7… ## $ black &lt;dbl&gt; 0.012213740, 0.017090069, 0.079514240, 0.030640… 4.2.1 Exercise Recreate a plot from the previous chapter using our newly imported acs tibble object. ggplot(acs, aes(x = bach, y = med_house_income)) + geom_point(alpha = 0.25) + labs(x = &quot;% of population with a Bachelor&#39;s Degree&quot;, y = &quot;Median Household Income&quot;, title = &quot;Relationship between Education and Income&quot;) 4.3 Other common data formats While csv files are going to be the most ubiquitous, you will invariably run into other data formats. The workflow is almost always the same. If you want to read excel files, you can use the function readxl::read_excel() from the readxl package. acs_xl &lt;- readxl::read_excel(&quot;data/acs_edu.xlsx&quot;) glimpse(acs_xl) ## Observations: 1,456 ## Variables: 7 ## $ med_house_income &lt;dbl&gt; 105735, 69625, 70679, 74528, 52885, 64100, 3709… ## $ less_than_hs &lt;dbl&gt; 0.02515518, 0.05773956, 0.09364548, 0.08426318,… ## $ hs_grad &lt;dbl&gt; 0.19568768, 0.25307125, 0.17332284, 0.25298192,… ## $ some_coll &lt;dbl&gt; 0.2211696, 0.3157248, 0.2726736, 0.3534052, 0.2… ## $ bach &lt;dbl&gt; 0.32473048, 0.26167076, 0.26677159, 0.23124279,… ## $ white &lt;dbl&gt; 0.8972737, 0.8849885, 0.7328322, 0.8235779, 0.7… ## $ black &lt;dbl&gt; 0.012213740, 0.017090069, 0.079514240, 0.030640… Another common format is a tsv which stands for tab separated format. readr::read_tsv() will be able to assist you here. If for some reason there are special delimiters like |, the readr::read_delim() function will work best. For example readr::read_delim(&quot;file-path&quot;, delim = &quot;|&quot;) would do the trick! Additionally, another extremely common data type is json which is short for javascript object notation. json is a data type that you will usually not read directly from a text file but interact with from an API. If you do happen to encounter a json flat text file, use the jsonlite package. jsonlite::read_json(). In the next chapter we will begin to work with dplyr and start getting hands on with our data. "],
["general-data-manipulation.html", "Chapter 5 General data manipulation 5.1 scenario: 5.2 Selecting Rows 5.3 filter", " Chapter 5 General data manipulation You may have heard of the 80/20 rule—or at least one of the many 80/20 rules. Data scientists are often fond of emphasising that 80% of their work is data cleaning and the other 20% is analysis and modeling this is all to say that you will find yourself with messy, unsanitized, gross, not fun to look at data most of the time because of this, it’s really important that we have the skills to clean our data right now we’re going to go over the foundational skills we will learn how to select columns and rows, filter data, and create new columns and variables we will be using functions from the package dplyr which is imported from the tidyverse recall how to load the tidyverse we’ll read in the ACS_1317_TRACT.csv file located in the data directory putting this together the file path is data/ACS_1317_TRACT.csv. store it in the variable acs_raw 5.1 scenario: a local non-profit is interested in learning about the demographic characteristics of the greater boston area. They are specifically interested to learn more about the relationship between the age, race, and economic status. They’ve come to you to provide them with the relevant data. you have acces to the annual BARI census data and you will curate the data for them. They define the greater boston area as Suffolk, Middlesex, and Norfolk counties. before we go ahead and start cleaning this data, we need to learn the tools to do so. Please bear with me! library(tidyverse) acs_raw &lt;- read_csv(&quot;data/ACS_1317_TRACT.csv&quot;) glimpse(acs_raw) ## Observations: 1,478 ## Variables: 59 ## $ ct_id_10 &lt;dbl&gt; 25027728100, 25027729200, 25027730700, 2502… ## $ name &lt;chr&gt; &quot;Census Tract 7281, Worcester County, Massa… ## $ total_pop &lt;dbl&gt; 4585, 2165, 6917, 7278, 5059, 6632, 3259, 2… ## $ pop_den &lt;dbl&gt; 332.5741, 1069.6977, 2112.9526, 1345.5905, … ## $ sex_ratio &lt;dbl&gt; 1.1315667, 1.3179872, 1.1329016, 1.1156977,… ## $ age_u18 &lt;dbl&gt; 0.2340240, 0.1810624, 0.1705942, 0.2033526,… ## $ age1834 &lt;dbl&gt; 0.2023991, 0.1510393, 0.2143993, 0.2272602,… ## $ age3564 &lt;dbl&gt; 0.3980371, 0.4609700, 0.4371838, 0.4359714,… ## $ age_o65 &lt;dbl&gt; 0.1655398, 0.2069284, 0.1778228, 0.1334158,… ## $ for_born &lt;dbl&gt; 0.04383860, 0.08729792, 0.20586960, 0.15526… ## $ white &lt;dbl&gt; 0.8972737, 0.8849885, 0.7328322, 0.8235779,… ## $ black &lt;dbl&gt; 0.012213740, 0.017090069, 0.079514240, 0.03… ## $ asian &lt;dbl&gt; 0.006324973, 0.021709007, 0.019950846, 0.03… ## $ hispanic &lt;dbl&gt; 0.070229008, 0.047575058, 0.136330779, 0.07… ## $ two_or_more &lt;dbl&gt; 0.012431843, 0.027713626, 0.017348562, 0.01… ## $ eth_het &lt;dbl&gt; -17032656, -3685242, -26905553, -36365806, … ## $ med_house_income &lt;dbl&gt; 105735, 69625, 70679, 74528, 52885, 64100, … ## $ pub_assist &lt;dbl&gt; 0.020782396, 0.004667445, 0.021067926, 0.03… ## $ gini &lt;dbl&gt; 0.4084, 0.3886, 0.4693, 0.4052, 0.5327, 0.4… ## $ fam_pov_per &lt;dbl&gt; 0.04754601, 0.06521739, 0.05843440, 0.02486… ## $ unemp_rate &lt;dbl&gt; 0.03361345, 0.03127572, 0.06124498, 0.03983… ## $ total_house_h &lt;dbl&gt; 1636, 857, 2753, 2878, 2326, 2635, 1245, 80… ## $ fam_house_per &lt;dbl&gt; 0.7970660, 0.6977830, 0.6589175, 0.6567060,… ## $ fem_head_per &lt;dbl&gt; 0.08985330, 0.12018670, 0.11442063, 0.12126… ## $ same_sex_coup_per &lt;dbl&gt; 0.00000000, 0.00000000, 0.00000000, 0.00000… ## $ grand_head_per &lt;dbl&gt; 0.000000000, 0.005834306, 0.000000000, 0.00… ## $ less_than_hs &lt;dbl&gt; 0.02515518, 0.05773956, 0.09364548, 0.08426… ## $ hs_grad &lt;dbl&gt; 0.19568768, 0.25307125, 0.17332284, 0.25298… ## $ some_coll &lt;dbl&gt; 0.2211696, 0.3157248, 0.2726736, 0.3534052,… ## $ bach &lt;dbl&gt; 0.32473048, 0.26167076, 0.26677159, 0.23124… ## $ master &lt;dbl&gt; 0.15942502, 0.09705160, 0.12059807, 0.06714… ## $ prof &lt;dbl&gt; 0.0405096374, 0.0098280098, 0.0397403108, 0… ## $ doc &lt;dbl&gt; 0.033322444, 0.004914005, 0.033248082, 0.00… ## $ commute_less10 &lt;dbl&gt; 0.07874016, 0.25109361, 0.05369894, 0.14119… ## $ commute1030 &lt;dbl&gt; 0.5131234, 0.4636920, 0.6620965, 0.3941685,… ## $ commute3060 &lt;dbl&gt; 0.33114611, 0.18110236, 0.17709226, 0.31263… ## $ commute6090 &lt;dbl&gt; 0.055555556, 0.082239720, 0.086832334, 0.13… ## $ commute_over90 &lt;dbl&gt; 0.021434821, 0.021872266, 0.020279920, 0.01… ## $ by_auto &lt;dbl&gt; 0.9267791, 0.9704861, 0.9248285, 0.9037018,… ## $ by_pub_trans &lt;dbl&gt; 0.000000000, 0.004340278, 0.020301783, 0.01… ## $ by_bike &lt;dbl&gt; 0.002879473, 0.000000000, 0.000000000, 0.00… ## $ by_walk &lt;dbl&gt; 0.002468120, 0.012152778, 0.004938272, 0.02… ## $ total_house_units &lt;dbl&gt; 1701, 886, 2928, 3181, 2511, 2713, 1581, 85… ## $ vacant_unit_per &lt;dbl&gt; 0.03821282, 0.03273138, 0.05976776, 0.09525… ## $ renters_per &lt;dbl&gt; 0.1088020, 0.2100350, 0.2804214, 0.3425990,… ## $ home_own_per &lt;dbl&gt; 0.8911980, 0.7899650, 0.7195786, 0.6574010,… ## $ med_gross_rent &lt;dbl&gt; 1640, 894, 1454, 954, 1018, 867, 910, 1088,… ## $ med_home_val &lt;dbl&gt; 349000, 230200, 207200, 268400, 223200, 232… ## $ med_yr_built_raw &lt;dbl&gt; 1988, 1955, 1959, 1973, 1964, 1966, 1939, 1… ## $ med_yr_built &lt;chr&gt; &quot;1980 to 1989&quot;, &quot;1950 to 1959&quot;, &quot;1950 to 19… ## $ med_yr_moved_inraw &lt;dbl&gt; 2004, 2003, 2007, 2006, 2006, 2000, 2011, 2… ## $ med_yr_rent_moved_in &lt;dbl&gt; 2012, 2010, 2012, 2011, 2011, 2009, 2012, 2… ## $ area_acres &lt;dbl&gt; 9407.9167, 1294.2828, 2123.4927, 3581.9026,… ## $ town_id &lt;dbl&gt; 134, 321, 348, 185, 153, 151, 316, 348, 28,… ## $ town &lt;chr&gt; &quot;HOLDEN&quot;, &quot;WEST BOYLSTON&quot;, &quot;WORCESTER&quot;, &quot;MI… ## $ fips_stco &lt;dbl&gt; 25027, 25027, 25027, 25027, 25027, 25027, 2… ## $ county &lt;chr&gt; &quot;WORCESTER&quot;, &quot;WORCESTER&quot;, &quot;WORCESTER&quot;, &quot;WOR… ## $ area_acr_1 &lt;dbl&gt; 23241.514, 8867.508, 24609.965, 9615.644, 1… ## $ m_atown &lt;chr&gt; &quot;HOLDEN&quot;, &quot;WEST BOYLSTON&quot;, &quot;WORCESTER&quot;, &quot;MI… This is the dataset from which acs_edu was created. We will work to create the same dataset. For a refresher the columns were: &quot;med_house_income, less_than_hs, hs_grad, some_coll, bach, white, and black. glimpse(read_csv(&quot;data/acs_edu.csv&quot;)) ## Observations: 1,456 ## Variables: 7 ## $ med_house_income &lt;dbl&gt; 105735, 69625, 70679, 74528, 52885, 64100, 3709… ## $ less_than_hs &lt;dbl&gt; 0.02515518, 0.05773956, 0.09364548, 0.08426318,… ## $ hs_grad &lt;dbl&gt; 0.19568768, 0.25307125, 0.17332284, 0.25298192,… ## $ some_coll &lt;dbl&gt; 0.2211696, 0.3157248, 0.2726736, 0.3534052, 0.2… ## $ bach &lt;dbl&gt; 0.32473048, 0.26167076, 0.26677159, 0.23124279,… ## $ white &lt;dbl&gt; 0.8972737, 0.8849885, 0.7328322, 0.8235779, 0.7… ## $ black &lt;dbl&gt; 0.012213740, 0.017090069, 0.079514240, 0.030640… to do so we use the function select(). Look at the help documentation by running ?select() inside of the console. What are the arguments? - .data and .... We’ll tackle this one by one. - .data: “A tbl.” - read this as “A tibble, or data frame”. - for those of you who are curious, tbl is the formal object class of a tibble. a tibble is still a data frame - this means that the first argument will be passed the acs_raw object - ...: One or more unquoted expressions separated by commas. You can treat variable names like they are positions, so you can use expressions like x:y to select ranges of variables. this one is a little bit more complex. ... referred to as “dots”. This really means we can pass any number of other arguments to select() here the ... will be ways of referring to the columns we want. and there are a number of ways we can referrer to which columns we want we can: write the name (unquoted) of the columns—i.e. i want the column col_x would be select(.data, col_x) write the position of the column—i.e. i want the first column would be select(.data, 1) There are also a number of select helpers of which we will go over a few one behavior that you should notice is that select will always return a tibble, even if we don’t sepcify any columns to select try using the select function on acs_raw without passing any column specifications to ... select(acs_raw) ## # A tibble: 1,478 x 0 select the median house hold income column (med_house_income) select(acs_raw, med_house_income) ## # A tibble: 1,478 x 1 ## med_house_income ## &lt;dbl&gt; ## 1 105735 ## 2 69625 ## 3 70679 ## 4 74528 ## 5 52885 ## 6 64100 ## 7 37093 ## 8 87750 ## 9 97417 ## 10 43384 ## # … with 1,468 more rows as the documentation notes we can select a range of columns using col_x:col_y select the columns relating to education from less than high school to doctoral select(acs_raw, less_than_hs:doc) ## # A tibble: 1,478 x 7 ## less_than_hs hs_grad some_coll bach master prof doc ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0252 0.196 0.221 0.325 0.159 0.0405 0.0333 ## 2 0.0577 0.253 0.316 0.262 0.0971 0.00983 0.00491 ## 3 0.0936 0.173 0.273 0.267 0.121 0.0397 0.0332 ## 4 0.0843 0.253 0.353 0.231 0.0671 0.00616 0.00481 ## 5 0.145 0.310 0.283 0.168 0.0879 0.00343 0.00158 ## 6 0.0946 0.294 0.317 0.192 0.0858 0.0161 0 ## 7 0.253 0.394 0.235 0.101 0.0155 0.000484 0 ## 8 0.0768 0.187 0.185 0.272 0.145 0.0569 0.0782 ## 9 0.0625 0.254 0.227 0.284 0.127 0.0223 0.0236 ## 10 0.207 0.362 0.262 0.124 0.0353 0 0.00972 ## # … with 1,468 more rows though you will likely not use it too often, it’s still important to be comfortable with column index (position) selecting select the 1st, 5th, and 10th columns select(acs_raw, 1, 5, 10) ## # A tibble: 1,478 x 3 ## ct_id_10 sex_ratio for_born ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 25027728100 1.13 0.0438 ## 2 25027729200 1.32 0.0873 ## 3 25027730700 1.13 0.206 ## 4 25027744200 1.12 0.155 ## 5 25027709701 1.30 0.106 ## 6 25027735100 1.11 0.0280 ## 7 25027754300 1.25 0.188 ## 8 25027730802 0.908 0.198 ## 9 25027717100 0.990 0.0797 ## 10 25027732600 1.19 0.210 ## # … with 1,468 more rows 5.1.0.1 tidyselect helpers we use the tidyselect helpers in the ... argument starts_with(): a string to search that columns start with find all columns that start with &quot;med&quot; select(acs_raw, starts_with(&quot;med&quot;)) ## # A tibble: 1,478 x 7 ## med_house_income med_gross_rent med_home_val med_yr_built_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 105735 1640 349000 1988 ## 2 69625 894 230200 1955 ## 3 70679 1454 207200 1959 ## 4 74528 954 268400 1973 ## 5 52885 1018 223200 1964 ## 6 64100 867 232700 1966 ## 7 37093 910 170900 1939 ## 8 87750 1088 270100 1939 ## 9 97417 1037 379600 1981 ## 10 43384 1017 156500 1939 ## # … with 1,468 more rows, and 3 more variables: med_yr_built &lt;chr&gt;, ## # med_yr_moved_inraw &lt;dbl&gt;, med_yr_rent_moved_in &lt;dbl&gt; ends_with(): a string to search that columns end with select columns that end with &quot;per&quot; select(acs_raw, ends_with(&quot;per&quot;)) ## # A tibble: 1,478 x 8 ## fam_pov_per fam_house_per fem_head_per same_sex_coup_p… grand_head_per ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0475 0.797 0.0899 0 0 ## 2 0.0652 0.698 0.120 0 0.00583 ## 3 0.0584 0.659 0.114 0 0 ## 4 0.0249 0.657 0.121 0 0 ## 5 0.198 0.531 0.158 0 0.00946 ## 6 0.0428 0.665 0.0603 0 0.0353 ## 7 0.0762 0.632 0.227 0 0.00643 ## 8 0.101 0.636 0.0582 0.297 0.0260 ## 9 0.0149 0.758 0.0721 0 0.00434 ## 10 0.0954 0.460 0.225 0 0.0279 ## # … with 1,468 more rows, and 3 more variables: vacant_unit_per &lt;dbl&gt;, ## # renters_per &lt;dbl&gt;, home_own_per &lt;dbl&gt; contains(): a string to search for in the column headers the string that we are searching for can be at any position find any column that contains the string &quot;yr&quot; select(acs_raw, contains(&quot;yr&quot;)) ## # A tibble: 1,478 x 4 ## med_yr_built_raw med_yr_built med_yr_moved_inraw med_yr_rent_moved_in ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1988 1980 to 1989 2004 2012 ## 2 1955 1950 to 1959 2003 2010 ## 3 1959 1950 to 1959 2007 2012 ## 4 1973 1970 to 1979 2006 2011 ## 5 1964 1960 to 1969 2006 2011 ## 6 1966 1960 to 1969 2000 2009 ## 7 1939 Prior to 1940 2011 2012 ## 8 1939 Prior to 1940 2006 2012 ## 9 1981 1980 to 1989 2004 2012 ## 10 1939 Prior to 1940 2011 NA ## # … with 1,468 more rows everything(): helpful when you want to move some columns to the front and dont care about the order of others takes no arguments select the town, county, then everything else select(acs_raw, town, county, everything()) ## # A tibble: 1,478 x 59 ## town county ct_id_10 name total_pop pop_den sex_ratio age_u18 age1834 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 HOLD… WORCE… 2.50e10 Cens… 4585 333. 1.13 0.234 0.202 ## 2 WEST… WORCE… 2.50e10 Cens… 2165 1070. 1.32 0.181 0.151 ## 3 WORC… WORCE… 2.50e10 Cens… 6917 2113. 1.13 0.171 0.214 ## 4 MILF… WORCE… 2.50e10 Cens… 7278 1346. 1.12 0.203 0.227 ## 5 LEOM… WORCE… 2.50e10 Cens… 5059 2894. 1.30 0.177 0.203 ## 6 LEIC… WORCE… 2.50e10 Cens… 6632 472. 1.11 0.163 0.237 ## 7 WEBS… WORCE… 2.50e10 Cens… 3259 8022. 1.25 0.191 0.326 ## 8 WORC… WORCE… 2.50e10 Cens… 2097 5191. 0.908 0.202 0.183 ## 9 BERL… WORCE… 2.50e10 Cens… 3098 239. 0.990 0.188 0.150 ## 10 WORC… WORCE… 2.50e10 Cens… 3982 17065. 1.19 0.244 0.286 ## # … with 1,468 more rows, and 50 more variables: age3564 &lt;dbl&gt;, ## # age_o65 &lt;dbl&gt;, for_born &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;, asian &lt;dbl&gt;, ## # hispanic &lt;dbl&gt;, two_or_more &lt;dbl&gt;, eth_het &lt;dbl&gt;, ## # med_house_income &lt;dbl&gt;, pub_assist &lt;dbl&gt;, gini &lt;dbl&gt;, ## # fam_pov_per &lt;dbl&gt;, unemp_rate &lt;dbl&gt;, total_house_h &lt;dbl&gt;, ## # fam_house_per &lt;dbl&gt;, fem_head_per &lt;dbl&gt;, same_sex_coup_per &lt;dbl&gt;, ## # grand_head_per &lt;dbl&gt;, less_than_hs &lt;dbl&gt;, hs_grad &lt;dbl&gt;, ## # some_coll &lt;dbl&gt;, bach &lt;dbl&gt;, master &lt;dbl&gt;, prof &lt;dbl&gt;, doc &lt;dbl&gt;, ## # commute_less10 &lt;dbl&gt;, commute1030 &lt;dbl&gt;, commute3060 &lt;dbl&gt;, ## # commute6090 &lt;dbl&gt;, commute_over90 &lt;dbl&gt;, by_auto &lt;dbl&gt;, ## # by_pub_trans &lt;dbl&gt;, by_bike &lt;dbl&gt;, by_walk &lt;dbl&gt;, ## # total_house_units &lt;dbl&gt;, vacant_unit_per &lt;dbl&gt;, renters_per &lt;dbl&gt;, ## # home_own_per &lt;dbl&gt;, med_gross_rent &lt;dbl&gt;, med_home_val &lt;dbl&gt;, ## # med_yr_built_raw &lt;dbl&gt;, med_yr_built &lt;chr&gt;, med_yr_moved_inraw &lt;dbl&gt;, ## # med_yr_rent_moved_in &lt;dbl&gt;, area_acres &lt;dbl&gt;, town_id &lt;dbl&gt;, ## # fips_stco &lt;dbl&gt;, area_acr_1 &lt;dbl&gt;, m_atown &lt;chr&gt; 5.2 Selecting Rows like we can select columns we can also select rows. however rows do not have names. we select the rows based on position unlike select, if we do not specify any arguments to ... it will return the entire data frame slice(acs_raw) ## # A tibble: 1,478 x 59 ## ct_id_10 name total_pop pop_den sex_ratio age_u18 age1834 age3564 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.50e10 Cens… 4585 333. 1.13 0.234 0.202 0.398 ## 2 2.50e10 Cens… 2165 1070. 1.32 0.181 0.151 0.461 ## 3 2.50e10 Cens… 6917 2113. 1.13 0.171 0.214 0.437 ## 4 2.50e10 Cens… 7278 1346. 1.12 0.203 0.227 0.436 ## 5 2.50e10 Cens… 5059 2894. 1.30 0.177 0.203 0.430 ## 6 2.50e10 Cens… 6632 472. 1.11 0.163 0.237 0.439 ## 7 2.50e10 Cens… 3259 8022. 1.25 0.191 0.326 0.380 ## 8 2.50e10 Cens… 2097 5191. 0.908 0.202 0.183 0.466 ## 9 2.50e10 Cens… 3098 239. 0.990 0.188 0.150 0.462 ## 10 2.50e10 Cens… 3982 17065. 1.19 0.244 0.286 0.342 ## # … with 1,468 more rows, and 51 more variables: age_o65 &lt;dbl&gt;, ## # for_born &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;, asian &lt;dbl&gt;, hispanic &lt;dbl&gt;, ## # two_or_more &lt;dbl&gt;, eth_het &lt;dbl&gt;, med_house_income &lt;dbl&gt;, ## # pub_assist &lt;dbl&gt;, gini &lt;dbl&gt;, fam_pov_per &lt;dbl&gt;, unemp_rate &lt;dbl&gt;, ## # total_house_h &lt;dbl&gt;, fam_house_per &lt;dbl&gt;, fem_head_per &lt;dbl&gt;, ## # same_sex_coup_per &lt;dbl&gt;, grand_head_per &lt;dbl&gt;, less_than_hs &lt;dbl&gt;, ## # hs_grad &lt;dbl&gt;, some_coll &lt;dbl&gt;, bach &lt;dbl&gt;, master &lt;dbl&gt;, prof &lt;dbl&gt;, ## # doc &lt;dbl&gt;, commute_less10 &lt;dbl&gt;, commute1030 &lt;dbl&gt;, commute3060 &lt;dbl&gt;, ## # commute6090 &lt;dbl&gt;, commute_over90 &lt;dbl&gt;, by_auto &lt;dbl&gt;, ## # by_pub_trans &lt;dbl&gt;, by_bike &lt;dbl&gt;, by_walk &lt;dbl&gt;, ## # total_house_units &lt;dbl&gt;, vacant_unit_per &lt;dbl&gt;, renters_per &lt;dbl&gt;, ## # home_own_per &lt;dbl&gt;, med_gross_rent &lt;dbl&gt;, med_home_val &lt;dbl&gt;, ## # med_yr_built_raw &lt;dbl&gt;, med_yr_built &lt;chr&gt;, med_yr_moved_inraw &lt;dbl&gt;, ## # med_yr_rent_moved_in &lt;dbl&gt;, area_acres &lt;dbl&gt;, town_id &lt;dbl&gt;, ## # town &lt;chr&gt;, fips_stco &lt;dbl&gt;, county &lt;chr&gt;, area_acr_1 &lt;dbl&gt;, ## # m_atown &lt;chr&gt; positive integers slice(acs_raw) ## # A tibble: 1,478 x 59 ## ct_id_10 name total_pop pop_den sex_ratio age_u18 age1834 age3564 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.50e10 Cens… 4585 333. 1.13 0.234 0.202 0.398 ## 2 2.50e10 Cens… 2165 1070. 1.32 0.181 0.151 0.461 ## 3 2.50e10 Cens… 6917 2113. 1.13 0.171 0.214 0.437 ## 4 2.50e10 Cens… 7278 1346. 1.12 0.203 0.227 0.436 ## 5 2.50e10 Cens… 5059 2894. 1.30 0.177 0.203 0.430 ## 6 2.50e10 Cens… 6632 472. 1.11 0.163 0.237 0.439 ## 7 2.50e10 Cens… 3259 8022. 1.25 0.191 0.326 0.380 ## 8 2.50e10 Cens… 2097 5191. 0.908 0.202 0.183 0.466 ## 9 2.50e10 Cens… 3098 239. 0.990 0.188 0.150 0.462 ## 10 2.50e10 Cens… 3982 17065. 1.19 0.244 0.286 0.342 ## # … with 1,468 more rows, and 51 more variables: age_o65 &lt;dbl&gt;, ## # for_born &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;, asian &lt;dbl&gt;, hispanic &lt;dbl&gt;, ## # two_or_more &lt;dbl&gt;, eth_het &lt;dbl&gt;, med_house_income &lt;dbl&gt;, ## # pub_assist &lt;dbl&gt;, gini &lt;dbl&gt;, fam_pov_per &lt;dbl&gt;, unemp_rate &lt;dbl&gt;, ## # total_house_h &lt;dbl&gt;, fam_house_per &lt;dbl&gt;, fem_head_per &lt;dbl&gt;, ## # same_sex_coup_per &lt;dbl&gt;, grand_head_per &lt;dbl&gt;, less_than_hs &lt;dbl&gt;, ## # hs_grad &lt;dbl&gt;, some_coll &lt;dbl&gt;, bach &lt;dbl&gt;, master &lt;dbl&gt;, prof &lt;dbl&gt;, ## # doc &lt;dbl&gt;, commute_less10 &lt;dbl&gt;, commute1030 &lt;dbl&gt;, commute3060 &lt;dbl&gt;, ## # commute6090 &lt;dbl&gt;, commute_over90 &lt;dbl&gt;, by_auto &lt;dbl&gt;, ## # by_pub_trans &lt;dbl&gt;, by_bike &lt;dbl&gt;, by_walk &lt;dbl&gt;, ## # total_house_units &lt;dbl&gt;, vacant_unit_per &lt;dbl&gt;, renters_per &lt;dbl&gt;, ## # home_own_per &lt;dbl&gt;, med_gross_rent &lt;dbl&gt;, med_home_val &lt;dbl&gt;, ## # med_yr_built_raw &lt;dbl&gt;, med_yr_built &lt;chr&gt;, med_yr_moved_inraw &lt;dbl&gt;, ## # med_yr_rent_moved_in &lt;dbl&gt;, area_acres &lt;dbl&gt;, town_id &lt;dbl&gt;, ## # town &lt;chr&gt;, fips_stco &lt;dbl&gt;, county &lt;chr&gt;, area_acr_1 &lt;dbl&gt;, ## # m_atown &lt;chr&gt; the n() helper negative integers 5.3 filter logical operators mutate i need to introduce measures of central tendency and summar stats in between this groups summarizing using the name column I can consider introducing string methods - this would probably be better done with text reviews or something "],
["visualizing-trends-and-relationships.html", "Chapter 6 Visualizing Trends and Relationships 6.1 Univariate visualizations 6.2 Bivariate visualizations 6.3 Expanding bivariate visualizations to trivariate &amp; other tri-variate 6.4 The Grammar of Layered Graphics", " Chapter 6 Visualizing Trends and Relationships library(tidyverse) acs_messy &lt;- read_csv(&quot;data/ACS_1317_TRACT.csv&quot;) ## Parsed with column specification: ## cols( ## .default = col_double(), ## name = col_character(), ## med_yr_built = col_character(), ## town = col_character(), ## county = col_character(), ## m_atown = col_character() ## ) ## See spec(...) for full column specifications. acs &lt;- acs_messy %&gt;% separate(name, sep = &quot;, &quot;, into = c(&quot;tract&quot;, &quot;county&quot;, &quot;state&quot;)) %&gt;% mutate(tract = str_remove(tract, &quot;Census Tract &quot;)) %&gt;% na.omit() most data analyses start with a visualization. the data we have will dictate the type of visualizations we create there are many many different ways in which data can be represented generally these can be bucketed into a few major categories numeric integer double character think groups, factors, nominal, anything that doesn’t have a numeric value that makes sense to count, aggregate, etc. time / order 6.1 Univariate visualizations what are we looking for in univariate visualizations? the shape of the distribution measures of central tendency where do the data cluster? is there a center? more than one? how much variation is in the data? is the distribution flatter or steeper? 6.1.1 histogram puts data into n groups or bins or buckets. ggplot calls them bins you can identify how many obs fit into a bucket ggplot(acs, aes(age_u18)) + geom_histogram(bins = 15) 6.1.2 density plot A density plot is a representation of the distribution of a numeric variable visualizes the distribution of data over a continuous interval it’s called a density plot because it uses a kernel density. you do not need to know what this is, just that it shows a continuous representation of the distribution unlike histograms you cannot determine how many obs fall in a bucket as there are no buckets. ggplot(acs, aes(age_u18)) + geom_density() 6.1.3 box plot box plots are another way to show the distribution unlike histograms and density plots which show the shape of the distribution box plots are concerned with illustrating any potential outliers aside: an outlier is a value that differs substantially from other obs based on 5 summary values: the first quartile median (the middle value) the third quartile the minimum and the maximum: these aren’t actually the max and min, these are we have to set this aesthetic to y refs: https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51 ggplot(acs, aes(y = age_u18)) + geom_boxplot() its easier to evaluate a box plot when it’s horizontal. we can flip any ggplot with a coord_flip() layer ggplot(acs, aes(y = age_u18)) + geom_boxplot() + coord_flip() 6.1.3.1 understanding the box plot 6.2 Bivariate visualizations with bi-variate relationships we’re looking to answer, in general, if one variable affects the other. we usually will be comparing two numeric variables or one numeric and one categorical variable in the former situtation we’re looking to see if there is a related trend, i.e. when one goes up does the other go down or vice versa in the latter scenario, we want to know if the distribution of the data changes for different groups 6.2.1 scatter plot (2 continuous) we made one previously this is two continuous on each axis. the variable of interest is on the y example: we can hypothesize that where there are more under 18 there are more families we can ask how does the prop of population under 18 vary with prop of family households? when there are many points (which is often the case w/ big data) we can change the transparency (often called opacity) so we can see where there is the most overlap. Inside of the geom_point() we set the alpha argument to a value between 0 and 1 where 1 is not transparent and 0 is invisible. this is artistic preference and there is no one true answer ggplot(acs, aes(fam_house_per, age_u18)) + geom_point(alpha = 0.25) 6.2.2 boxplot (1 continuous 1 categorical) we can use boxplots to compare groups for this, we set the categorical variable to the x aesthetic ggplot(acs, aes(county, age_u18)) + geom_boxplot() + coord_flip() 6.2.3 barplot (1 categorical 1 continuous / discrete) the geom_bar() will count the number observations of the specified categorical variables ggplot(acs, aes(county)) + geom_bar() + coord_flip() 6.2.4 lollipop chart barplot’s more fun cousin, the lollipop chart the package ggalt makes a geom for us so we don’t have to create it manually we do, however, have to count the observations ourself. we use the function count() to do this. the arguments are x, or the tibble, and ... these are the columns we want to count important note: in the tidyverse, the first argument is almost always the tibble we are working with this will become very useful at a later point remember, to install packages, navigate to the console and use the function install.packages(&quot;pkg-name&quot;). library(ggalt) ## Registered S3 methods overwritten by &#39;ggalt&#39;: ## method from ## grid.draw.absoluteGrob ggplot2 ## grobHeight.absoluteGrob ggplot2 ## grobWidth.absoluteGrob ggplot2 ## grobX.absoluteGrob ggplot2 ## grobY.absoluteGrob ggplot2 acs_counties &lt;- count(acs, county) ggplot(acs_counties, aes(county, n)) + geom_lollipop() + coord_flip() ridgelines (1 continuous 1 categorical) line chart (1 continuous 1 time), this is a unique case 6.3 Expanding bivariate visualizations to trivariate &amp; other tri-variate we can visualize other vcariables by setting further aesthetics. can set the color or fill, size, and shape we alreay did this previously when we set the color, let’s do that here. lets see how commuting by walking changes with the family house and under 18 pop set the color argument of the aes() function as color = by_walk it’s important you do this within the aesthetics function ggplot(acs, aes(fam_house_per, age_u18, color = by_auto)) + geom_point() we can add size to this as well by setting the size aesthetic lets see if the more female headed house holds there are affects commuting by car as minors increases ggplot(acs, aes(fam_house_per, age_u18, color = by_auto, size = fem_head_per)) + geom_point(alpha = .2) from this chart we can see quite a few things: as fam_house_per increases so does the under 18 pop, as both age_u18 and fam_house_per increase so does the rate of communiting by car as both age_u18 and fam_house_per so does female headed houses, but to a lesser degree this gives us a good idea of some relationships that we can test with our data at a later point minors_lm &lt;- lm(age_u18 ~ fam_house_per + by_auto + fem_head_per, data = acs) huxtable::huxreg(minors_lm) ## Registered S3 methods overwritten by &#39;broom.mixed&#39;: ## method from ## augment.lme broom ## augment.merMod broom ## glance.lme broom ## glance.merMod broom ## glance.stanreg broom ## tidy.brmsfit broom ## tidy.gamlss broom ## tidy.lme broom ## tidy.merMod broom ## tidy.rjags broom ## tidy.stanfit broom ## tidy.stanreg broom (1) (Intercept) 0.000&nbsp;&nbsp;&nbsp;&nbsp; (0.006)&nbsp;&nbsp;&nbsp; fam_house_per 0.245 *** (0.009)&nbsp;&nbsp;&nbsp; by_auto 0.016 *&nbsp;&nbsp; (0.007)&nbsp;&nbsp;&nbsp; fem_head_per 0.257 *** (0.012)&nbsp;&nbsp;&nbsp; N 1311&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; R2 0.564&nbsp;&nbsp;&nbsp;&nbsp; logLik 2444.648&nbsp;&nbsp;&nbsp;&nbsp; AIC -4879.296&nbsp;&nbsp;&nbsp;&nbsp; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05. Trivariate: grouped / stacked bar charts heatmaps 6.4 The Grammar of Layered Graphics recommended reading: A Layered Grammar of Graphics in R we will use a package called ggplot2 to do the visualizaiton of our data the gg in ggplot stands for “grammar of graphics”. once we can internalize the grammar, creating plots becomes rather easy we specify our aesthetics we add layers (hence the plus sign). these take values from the specified aesthetics can add multiple layers add aesthetics other than x and y. helps us visualize more dimensions of the data. we can use shape, color, and size 6.4.1 revisiting the cartesian plane x and y coordinates generally two numeric values on the x and y. think of the standards scatterplot (below) we also can place groups on one axis i.e. barchart (below) the y is usually the variable of interest as we move along the x axis (to the right) we can see how the y changes in response "],
["summary-statistics.html", "Chapter 7 Summary statistics", " Chapter 7 Summary statistics what is a summary stat? measures of central tendency measures of spread basic functions used mean, median, &amp; sd "],
["the-pipe.html", "Chapter 8 The pipe %&gt;% 8.1 Chaining functions", " Chapter 8 The pipe %&gt;% previously we have been working with one function at a time. it will become necessary to perform one function after another one way we could go about this is to write over the eisting object multiple times with an assignment &lt;- this is repetitive and hard to read we can utilize the forward pipe operator %&gt;% to chain functions together. from https://magrittr.tidyverse.org/: Basic piping x %&gt;% f is equivalent to f(x) x %&gt;% f(y) is equivalent to f(x, y) x %&gt;% f %&gt;% g %&gt;% h is equivalent to h(g(f(x))) from tidy soc sci 8.1 Chaining functions The true power of the tidyverse comes from it’s ability to chain functions after eachother. This is all enabled by the forward pipe operator %&gt;%. What it does: The pipe operator takes the output of it’s left hand side lhs and provides that output as the first argument in the function of the right hand side. Additionally, it exposes the lhs as a temporary variable .. Remember how I pointed out that the first argument for almost every function is the data? This is where that comes in handy. This allows us to use the pipe to chain together functions and “makes it more intuitive to both read and write” (magrittr vignette). You’ve seen how the first argument for every function here has been the data this is done purposefully to enable the use of the pipe. As always, the most helpful way to wrap your head around this is to see it in action. Let’s take one of the lines of code we used above and adapt it to use a pipe. We will select the name column of our data again. Previously we wrote select(data_frame, col_name). "],
["summarizing-the-tidy-way.html", "Chapter 9 summarizing the tidy way", " Chapter 9 summarizing the tidy way summarising data sets group_by() summarize() "],
["joining-data.html", "Chapter 10 joining data", " Chapter 10 joining data multiple data sets what is a join? the need for a common identifier join types: left inner right full (rare) anti-join (for removing data) appendix - style "]
]
