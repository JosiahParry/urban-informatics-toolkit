# Visual Analysis 


```{r, include=FALSE}
source("common.R")
```

## Data in the municipal context

The so called "proliferation of data" has created vast troves of data asking to be explored. We are, in essence, in the beginning of a new Gold Rush. But rather than discovering gold, today the gold is both being created an discovered. This explosion of data is the product of improved technology in both the collection and storage of data. 

If we focus our gaze towards the municipal government, the story is similar, progress is slower, and the data are more familiar. Local governments have been collecting data for centuries but until recently it was not always accessible, or even considered "data". Take the city of Boston as an example. Since the 19th century boston has been issuing and recording building permits. Through a massive digitization effort these permits are now accessible in an online database [^1]. Not only are governments slowly turning to modern methods of data storage, but they are also creating applications to encourage citizens to engage with their local governments. Mobile and web applications will hopefully facilitate greater interaction between citizen and government [^2]. Each and every one of these citizen to government interactions are recorded and stored in database—though not all are open and accessible to the citizen scientist. 

Boston has built a few mobile applications for its residents. Notable among these apps are the BOS:311[^3], ParkBoston[^4], the city's least favorite Boston PayTix[^5], and the new Blue Bikes[^6]. Through BOS:311 residents can communicate directly to the Department of Public Works by recording an issue, it's location, and even an image of the issue. Blue Bikes trips, 311 requests, and much more are provided to the public via Analyze Boston, Boston's data portal[^7]. 

This new availability of data has unintentionally altered the way in which scientists interact with data. For the purposes of scientific inquiry, scientists and analysts have historically been rather close to the data generation process. While we as residents and citizens interact with governmental agencies, it is not in the name of science. And the governmental agencies are engagin with residents in for the purpose of governance, not science. As such, much—if not all—of the open and public data that we interact within the urban informatics—and greater digital humanities—fields was not generated with the express purpose of being analyzed. This inherently changes the way in which analyses are approached. 

In approaching data of this nature, researchers have began embracing a paradigm of _exploratory data analysis_ (EDA). EDA is extremely useful for developing insights from data in which there were no a priori[^8] hypotheses. In their influential book R for Data Science, Garret Grolemund and Hadley Wickham describe this inductive approach of exploratory data analysis. 

> Data exploration is the art of looking at your data, rapidly generating hypotheses, quickly testing them, then repeating again and again and again. [^9]

When researchers set out to test a hypothesis they often will become closely involved with the data generation process. In this scenario, researchers are more likely to have preconceived hypotheses and expectiation of what they may find hidden in their data. 

This condition is often not the case when working with open data. We do not always know at the outset of what we are looking for. With open data—and any data really—you never know what you may find if you begin to dig. Whip out your hand shovel and prepare to upturn the soil. You might find seedlings that may sprout into your next study. 


## EDA lifecycle 

This chapter will introduce you to visual data exploration through the use of the R package `ggplot2`. You will ask questions of your data, visualize relationships, and draw inferences from the graphics you develop. 

The below image from R for Data Science is renowned for its representation of the data analysis workflow. The concept map encompasses the need to get data (import), clean it up (tidy), explore, and finally communicate insights. The box in blue is a representation of EDA. Within EDA we will find ourselves transforming our data—creating new variables, aggregating, etc.—visualizing it, and creating statistical models. 

![](https://d33wubrfki0l68.cloudfront.net/795c039ba2520455d833b4034befc8cf360a70ba/558a5/diagrams/data-science-explore.png)

This chapter will focus on the visualization step of EDA. We have all heard the trope that "an image is worth a thousand words." I'd take a leap and say that a good visualization is worth ten thousand words. An older statistical manual from the National Institute of Standards and Technology (NIST) beautifully lays out the role that visualization plays in EDA.

> The reason for the heavy reliance on graphics is that by its very nature the main role of EDA is to open-mindedly explore, and graphics gives the analysts unparalleled power to do so, enticing the data to reveal its structural secrets, and being always ready to gain some new, often unsuspected, insight into the data. In combination with the natural pattern-recognition capabilities that we all possess, graphics provides, of course, unparalleled power to carry this out.

[source](https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm)

In the following section, you will become acquainted with the graphical R package `ggplot2` for visual analysis and the American Community Survey. We will walk through the process building a chart from the ground up and drawing inferences from it along the way.


## The American Community Survey 

- we'll work with data from the american community survey. 
  - this is data you will get really familiar with 
- what is the acs and why do we love it?
  - https://www.vox.com/explainers/2015/12/3/9845152/acs-survey-defunded
  - random sample of individuals across the us 
    - random samples are used as they representative and statistically non-biased
  - the information is used to determine funding
  - tells us about age, ethnicity, country of origin, occupation, education, voting behavior, etc.
  - this information is available in the decennial census (in the constitution)
  - ACS tells us about rates rather than the actual number of people in a thing
  - one of the major problems is that some populations are under-represented
    - https://prospect.org/economy/insidious-way-underrepresent-minorities/
    

## A first visualization


```{r, include=FALSE}
library(tidyverse)
acs_edu <- read_csv("data/acs_edu.csv")
```

> What is the relationship between education and income?

we have a data frame loaded 
this is very similar to a table in excel
each column is a variable

```{r max.print=10}
acs_edu
```

we can visualize the relationship to get a better understanding. we can look at income and college grad rates

start building a visualization with `ggplot()` **function** with the `acs_edu` **object**.
Functions are characterised by the parentheses at the end of them. Functions do things. Objects hold information. 


```{r}
ggplot(acs_edu)
```

we add to this plot
determine what we want to plot with the aesthetics `aes()` function inside of the ggplot(). 
want to specify x and y. These are called arguments. To set argument we use the `=` sign.
set `x` to `bach` and `y` to `med_house_income`

```{r}
ggplot(acs_edu, aes(x = bach, y = med_house_income))
```

- notice how the plot is being filled a bit more?
- now we need to specify what type of plot we will be creating. 
- add geometry, or geoms. We use the plus sign `+` to signify that we are adding on top of the basic graph
- there are many different kinds of charts we can use we will get into these a bit more later.
- a common way of visualizing a relationship between two variables is with a scatterplot 
- a scatter plot graphs points for each x and y pair. you've likely made a few of these in your primary education
- to add points to the graph we use `geom_point()`, remember, we are _adding_ a layer so we use the plus sign
- for legibility we add each new layer on a new line. R will indent for you. Good style is important. We'll get into this later

```{r}
ggplot(acs_edu, aes(x = bach, y = med_house_income)) +
  geom_point()
```

- notice that there is a positive linear trend. 
- lets break that down:
  - when the point point up to the right, that is positive, down to the left is negative. 
    - for each unit we go up on the x (bach) we tend to go up on the y (hh income)
  - linear means it resembles a line
- what are we looking for in a scatter plot?
  - we're looking for low variation and a consistent pattern or line
  - we want the points to be very close
  - imagine we drew a line going through the middle of the points, we'd want each point to be either on that line or extremely close. if the line is further away, that means there is a lot more variation
- to finish this up we can add some informative labels
- we will add a labels layer with the function `labs()`
- give them more legible labels. we will give each axis a better name and give the plot a title
- the arguments we will set to the labs function are `x`, `y` and `title`. Rather intuitive, huh?
  - x = "% of population with a Bachelor's Degree"
  - y = "Median Household Income"
  - title = "Relationship between Education and Income"
- note that for each argument I have a new line. again, this helps with legibility

```{r}
ggplot(acs_edu, aes(x = bach, y = med_house_income)) +
  geom_point() +
  labs(x = "% of population with a Bachelor's Degree",
       y = "Median Household Income",
       title = "Relationship between Education and Income")
```

- what can we determine from this graph?
- in the sociology literature there is a lot about the education gap between white and black folks
- can we see this in a graph?
- we can modify our existing plot to illustrate this too. 
- we can map the % white to the color of the chart
- we add to this within the aesthetics. The `aes()`thetics is where we will determine things like size, group, shape, etc.
- set the `color` argument to the `white` column
- while we're at it, we can add a subtitle to inform that we're also coloring by % white


```{r}
ggplot(acs_edu, aes(x = bach, y = med_house_income, color = white)) +
  geom_point() +
  labs(x = "% of population with a Bachelor's Degree",
       y = "Median Household Income",
       title = "Relationship between Education and Income",
       subtitle = "Colored by whiteness") 
```

- what can we conclude now?

[^1]: Boston Building Permits: https://www.boston.gov/departments/inspectional-services/how-find-historical-permit-records
[^2]: Some note about co-production.
[^3]: BOS:311: https://itunes.apple.com/us/app/boston-citizens-connect/id330894558?mt=8
[^4]: ParkBoston: https://apps.apple.com/us/app/parkboston/id953579075
[^5]: Boston PayTix: https://apps.apple.com/us/app/boston-paytix/id1068651854
[^6]: BlueBikes:
[^7]: https://data.boston.gov/
[^8]: "Relating to or denoting reasoning or knowledge which proceeds from theoretical deduction rather than from observation or experience." [Oxford Dictionary](https://www.lexico.com/definition/a_priori)
[^9]: https://r4ds.had.co.nz/explore-intro.html

https://data.boston.gov/dataset/311-service-requests
https://data.boston.gov/dataset/blue-bikes-system-data


-------


#### Misc Notes:

- this chapter is to introduce the concept of exploratory data analysis
  - this should be done at a later point


- NIST EDA: https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm
- https://r4ds.had.co.nz/explore-intro.html
- iteration 
- this chapter focuses on visualization
- the process of exploratory anlaysis is naturally inductive

